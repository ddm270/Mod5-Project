{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_users.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['clean_review'].notna()]\n",
    "df = df[df['sent_class'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>label</th>\n",
       "      <th>release_date</th>\n",
       "      <th>metascore</th>\n",
       "      <th>user_score</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>sent_class</th>\n",
       "      <th>rating_sent</th>\n",
       "      <th>sp_lm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Continuum</td>\n",
       "      <td>John Mayer</td>\n",
       "      <td>Sony</td>\n",
       "      <td>2006-09-12</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Adult Alternative</td>\n",
       "      <td>The singer-songwriter's first album in three y...</td>\n",
       "      <td>ibadukefan</td>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>10.0</td>\n",
       "      <td>This is John Mayer in the zone.  This is where...</td>\n",
       "      <td>john mayer zone lives kind making rest career ...</td>\n",
       "      <td>441.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-0.3761</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>john mayer zone live kind make rest career kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Continuum</td>\n",
       "      <td>John Mayer</td>\n",
       "      <td>Sony</td>\n",
       "      <td>2006-09-12</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Adult Alternative</td>\n",
       "      <td>The singer-songwriter's first album in three y...</td>\n",
       "      <td>ToddW</td>\n",
       "      <td>2006-09-27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I give Little, Good John kudos for at least t...</td>\n",
       "      <td>give little good john kudos least turning ligh...</td>\n",
       "      <td>575.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.3651</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>give little good john kudos least turn light s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Continuum</td>\n",
       "      <td>John Mayer</td>\n",
       "      <td>Sony</td>\n",
       "      <td>2006-09-12</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Adult Alternative</td>\n",
       "      <td>The singer-songwriter's first album in three y...</td>\n",
       "      <td>ChristopherG.</td>\n",
       "      <td>2007-08-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>John Mayer... oh John Mayer. A talented blues...</td>\n",
       "      <td>john mayer oh john mayer talented bluesguitari...</td>\n",
       "      <td>653.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>john mayer oh john mayer talented bluesguitari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Continuum</td>\n",
       "      <td>John Mayer</td>\n",
       "      <td>Sony</td>\n",
       "      <td>2006-09-12</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Adult Alternative</td>\n",
       "      <td>The singer-songwriter's first album in three y...</td>\n",
       "      <td>jfrotylpe532</td>\n",
       "      <td>2012-12-21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>John Mayer brings a great sounding album as a ...</td>\n",
       "      <td>john mayer brings great sounding matter fact w...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>john mayer bring great sounding matter fact wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Continuum</td>\n",
       "      <td>John Mayer</td>\n",
       "      <td>Sony</td>\n",
       "      <td>2006-09-12</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Adult Alternative</td>\n",
       "      <td>The singer-songwriter's first album in three y...</td>\n",
       "      <td>ErinY</td>\n",
       "      <td>2006-09-12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>It is great to have John Mayer back. This alb...</td>\n",
       "      <td>great john mayer back definitely best really s...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.9001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>great john mayer back definitely good really s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0      title      artist label release_date  metascore user_score  \\\n",
       "0          0  Continuum  John Mayer  Sony   2006-09-12       67.0        8.9   \n",
       "1          1  Continuum  John Mayer  Sony   2006-09-12       67.0        8.9   \n",
       "2          2  Continuum  John Mayer  Sony   2006-09-12       67.0        8.9   \n",
       "3          3  Continuum  John Mayer  Sony   2006-09-12       67.0        8.9   \n",
       "4          4  Continuum  John Mayer  Sony   2006-09-12       67.0        8.9   \n",
       "\n",
       "               genre                                            summary  \\\n",
       "0  Adult Alternative  The singer-songwriter's first album in three y...   \n",
       "1  Adult Alternative  The singer-songwriter's first album in three y...   \n",
       "2  Adult Alternative  The singer-songwriter's first album in three y...   \n",
       "3  Adult Alternative  The singer-songwriter's first album in three y...   \n",
       "4  Adult Alternative  The singer-songwriter's first album in three y...   \n",
       "\n",
       "            name        date  rating  \\\n",
       "0     ibadukefan  2014-02-02    10.0   \n",
       "1          ToddW  2006-09-27     1.0   \n",
       "2  ChristopherG.  2007-08-01     3.0   \n",
       "3   jfrotylpe532  2012-12-21     8.0   \n",
       "4          ErinY  2006-09-12    10.0   \n",
       "\n",
       "                                              review  \\\n",
       "0  This is John Mayer in the zone.  This is where...   \n",
       "1   I give Little, Good John kudos for at least t...   \n",
       "2   John Mayer... oh John Mayer. A talented blues...   \n",
       "3  John Mayer brings a great sounding album as a ...   \n",
       "4   It is great to have John Mayer back. This alb...   \n",
       "\n",
       "                                        clean_review  length  word_count  \\\n",
       "0  john mayer zone lives kind making rest career ...   441.0        83.0   \n",
       "1  give little good john kudos least turning ligh...   575.0       102.0   \n",
       "2  john mayer oh john mayer talented bluesguitari...   653.0       117.0   \n",
       "3  john mayer brings great sounding matter fact w...   108.0        20.0   \n",
       "4  great john mayer back definitely best really s...   123.0        22.0   \n",
       "\n",
       "   sentiment  negative  neutral  positive  sent_class  rating_sent  \\\n",
       "0    -0.3761     0.154    0.728     0.118        -1.0          1.0   \n",
       "1    -0.3651     0.222    0.576     0.202        -1.0         -1.0   \n",
       "2     0.9371     0.057    0.678     0.266         1.0         -1.0   \n",
       "3     0.7964     0.000    0.497     0.503         1.0          1.0   \n",
       "4     0.9001     0.000    0.389     0.611         1.0          1.0   \n",
       "\n",
       "                                               sp_lm  \n",
       "0  john mayer zone live kind make rest career kno...  \n",
       "1  give little good john kudos least turn light s...  \n",
       "2  john mayer oh john mayer talented bluesguitari...  \n",
       "3  john mayer bring great sounding matter fact wa...  \n",
       "4  great john mayer back definitely good really s...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 83415 entries, 0 to 85499\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   title         83415 non-null  object \n",
      " 1   artist        83415 non-null  object \n",
      " 2   label         83042 non-null  object \n",
      " 3   release_date  83415 non-null  object \n",
      " 4   metascore     83415 non-null  float64\n",
      " 5   user_score    83415 non-null  object \n",
      " 6   genre         83415 non-null  object \n",
      " 7   summary       82114 non-null  object \n",
      " 8   name          83415 non-null  object \n",
      " 9   date          83415 non-null  object \n",
      " 10  rating        83415 non-null  float64\n",
      " 11  review        83415 non-null  object \n",
      " 12  clean_review  83415 non-null  object \n",
      " 13  length        83414 non-null  float64\n",
      " 14  word_count    83414 non-null  float64\n",
      " 15  sentiment     83414 non-null  float64\n",
      " 16  negative      83414 non-null  float64\n",
      " 17  neutral       83414 non-null  float64\n",
      " 18  positive      83414 non-null  float64\n",
      " 19  sent_class    83414 non-null  float64\n",
      " 20  rating_sent   83414 non-null  float64\n",
      " 21  sp_lm         83414 non-null  object \n",
      "dtypes: float64(10), object(12)\n",
      "memory usage: 14.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list=stopwords.words('english')+list(string.punctuation)+['album','albums', 'songs', 'song', 'music', 'like', 'one']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove all stopwords, punctuations & unimportant words from the reviews and make a list\n",
    "def reduce(text):\n",
    "    tokens = tokenizer.tokenize(text) # tokenize every review\n",
    "    removed = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "    return removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews = df['clean_review']\n",
    "target = df['sent_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all stopwords, punctuations & unimportant words from the reviews and make a list\n",
    "processed_data = list(map(reduce, clean_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_review = []\n",
    "for j in processed_data:\n",
    "    lem = ' '.join([lemmatizer.lemmatize(w) for w in j])\n",
    "    lem_review.append(lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "XL = lem_review\n",
    "yL = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_train, XL_test, yL_train, yL_test = train_test_split(XL, yL, test_size=0.2, random_state=1)\n",
    "tfVectorizer = TfidfVectorizer()\n",
    "\n",
    "XL_train_tf = tfVectorizer.fit_transform(XL_train)\n",
    "XL_test_tf = tfVectorizer.transform(XL_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting & predicting the Dummy Classifier (Baseline Model)\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dclf = DummyClassifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dclf.fit(XL_train_tf, yL_train)\n",
    "yL_preds = dclf.predict(XL_test_tf)\n",
    "print('dummy accuracy:',accuracy_score(yL_test, yL_preds),\n",
    "      'dummy forest f1:',f1_score(yL_test, yL_preds, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "rf_classifier.fit(XL_train_tf, yL_train)\n",
    "yL_preds = rf_classifier.predict(XL_test_tf)\n",
    "print('random forest accuracy:',accuracy_score(yL_test, yL_preds),\n",
    "      'random forest f1:',f1_score(yL_test, yL_preds, average = 'weighted'))\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes accuracy: 0.7851705328777798 naive bayes f1: 0.7110343514866779\n",
      "0:00:00.065859\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "nb_classifier.fit(XL_train_tf, yL_train)\n",
    "yL_preds = nb_classifier.predict(XL_test_tf)\n",
    "print('naive bayes accuracy:',accuracy_score(yL_test, yL_preds),\n",
    "      'naive bayes f1:',f1_score(yL_test, yL_preds, average = 'weighted'))\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier = SVC(kernel='rbf', C= 1.0, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support vector machine accuracy: 0.8900124918208316 support vector machine f1: 0.8908538384465301\n",
      "0:38:21.635190\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "svc_classifier.fit(XL_train_tf, yL_train)\n",
    "yL_preds = svc_classifier.predict(XL_test_tf)\n",
    "print('support vector machine accuracy:',accuracy_score(yL_test, yL_preds),\n",
    "      'support vector machine f1:',f1_score(yL_test, yL_preds, average = 'weighted'))\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid SearchCV Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_params = {'alpha': [0.01,0.03,0.05,0.07,0.09,0.11,0.13,0.15,0.17,0.19],\n",
    "              'fit_prior': [True, False],\n",
    "              'class_prior': [[-1,0,1],[1,0,-1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 40 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:    7.5s finished\n",
      "/Users/danielmocombe/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:488: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = np.log(class_prior)\n",
      "/Users/danielmocombe/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:488: RuntimeWarning: invalid value encountered in log\n",
      "  self.class_log_prior_ = np.log(class_prior)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.01, 0.03, 0.05, 0.07, 0.09, 0.11, 0.13,\n",
       "                                   0.15, 0.17, 0.19],\n",
       "                         'class_prior': [[-1, 0, 1], [1, 0, -1]],\n",
       "                         'fit_prior': [True, False]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_nb = GridSearchCV(nb_classifier, param_grid=nb_params, cv=7, scoring='accuracy', verbose =1, n_jobs=-1)\n",
    "grid_nb.fit(XL_train_tf, yL_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7696117078159256\n",
      "{'alpha': 0.01, 'class_prior': [1, 0, -1], 'fit_prior': True}\n",
      "MultinomialNB(alpha=0.01, class_prior=[1, 0, -1])\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid_nb.best_score_)\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_nb.best_params_)\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_nb.best_estimator_)\n",
    "#Identify the best score during fitting with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes accuracy: 0.7734221640592469 naive bayes f1: 0.6746073845032925\n"
     ]
    }
   ],
   "source": [
    "yL_preds = grid_nb.best_estimator_.predict(XL_test_tf)\n",
    "print('naive bayes accuracy:',accuracy_score(yL_test, yL_preds),\n",
    "      'naive bayes f1:',f1_score(yL_test, yL_preds, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with spaCy\n",
    "\n",
    "Modeling review text with spaCy was used to try to better process the large amount of text in the data and handle the context of the review and see if it resulted in better performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "XS = df['sp_lm']\n",
    "yS = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "XS_train, XS_test, yS_train, yS_test = train_test_split(XS, yS, test_size=0.2, random_state=1)\n",
    "tfVectorizer = TfidfVectorizer()\n",
    "\n",
    "XS_train_tf = tfVectorizer.fit_transform(XS_train)\n",
    "XS_test_tf = tfVectorizer.transform(XS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest accuracy: 0.8515852715483909 random forest f1: 0.8235248252766394\n",
      "0:08:16.000135\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "rf_classifier.fit(XS_train_tf, yS_train)\n",
    "yS_preds = rf_classifier.predict(XS_test_tf)\n",
    "print('random forest accuracy:',accuracy_score(yS_test, yS_preds),\n",
    "      'random forest f1:',f1_score(yS_test, yS_preds, average = 'weighted'))\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes accuracy: 0.7887097733626792 naive bayes f1: 0.7165917504732271\n",
      "0:00:00.081752\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "nb_classifier.fit(XS_train_tf, yS_train)\n",
    "yS_preds = nb_classifier.predict(XS_test_tf)\n",
    "print('naive bayes accuracy:',accuracy_score(yS_test, yS_preds),\n",
    "      'naive bayes f1:',f1_score(yS_test, yS_preds, average = 'weighted'))\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier = SVC(kernel='linear', C = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier = SVC(kernel='rbf', C= 1.0, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support vector machine accuracy: 0.7734221640592469 support vector machine f1: 0.8892753959425289\n",
      "0:43:17.802017\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "svc_classifier.fit(XS_train_tf, yS_train)\n",
    "yS_preds = svc_classifier.predict(XS_test_tf)\n",
    "print('support vector machine accuracy:',accuracy_score(yS_test, yL_preds),\n",
    "      'support vector machine f1:',f1_score(yS_test, yS_preds, average = 'weighted'))\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
